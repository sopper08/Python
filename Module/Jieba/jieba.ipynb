{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# jieba\n",
    "參考自: https://github.com/fxsjy/jieba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 目錄\n",
    "1. 模式簡介\n",
    "2. import jieba\n",
    "3. 字典增改\n",
    "    1. 載入字典\n",
    "    2. 調整字典\n",
    "4. 分詞\n",
    "    1. jieba.cut\n",
    "5. 基於TF-IDF算法的關鍵字提取\n",
    "    1. import jieba.analyse\n",
    "    2. analyse.extract_tags()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 模式簡介\n",
    "* 精確模式: 試圖將句子最精確地切開, 適合文本分析.\n",
    "* 全模式: 把句子可以成詞的詞語全都掃描出來.\n",
    "* 搜索引擎模式: 在精確模式的基礎上, 對長詞再次切分."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 字典增改\n",
    "\n",
    "**字典格式**: 一個詞一行, 一行分三部分用空格隔開: 詞語, 詞頻(可省略), 詞性(可省略)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.A 載入字典\n",
    "**jieba.load_userdict(file_name)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "jieba.load_userdict(\"userdict.txt\")\n",
    "# 字典參考自: http://tekibrain.blogspot.tw/2015/12/python-jieba-google.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.B 調整辭典\n",
    "* **add_word(word, freq=None, tag=None)**\n",
    "* **del_word(word)**\n",
    "* **suggest_freq(segment, tune=True)**: 調節詞頻."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 分詞\n",
    "* **jieba.cut(self, cut_all, HMM)**: \n",
    "    * 默認參數分別為: (str)需分詞的資料, (boolean)是否開啟全模式, (boolean)是否使用HMM模型\n",
    "* **jieba.lcut(self, cut_all, HMM)**: \n",
    "    * 同上, 但直接返回list.\n",
    "* **jieba.cut_for_search()**:\n",
    "    * 用於搜索模式.\n",
    "* **jieba.lcut_for_search()**:\n",
    "    * 同上, 但直接返回list.\n",
    "* **jieba.Tokenizer(dictionary=DEFAULT_DICT)**:\n",
    "    * 新建自定義分詞器, 可用於同時使用不同字典."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.A jieba.cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Mode: 我來/來到/臺灣/的/臺灣/臺灣大學/大學\n",
      "Full Mode: 我/來到/臺灣/的/臺灣大學\n",
      "精確模式: 阿明, 碩士, 畢業, 於, 台灣大學, 生物, 機電, 所, ，, 後來, 在家, 撿, 牛糞, 。\n",
      "搜尋引擎模式: 阿明, 碩士, 畢業, 於, 台灣, 大學, 台灣大學, 生物, 機電, 所, ，, 後來, 在家, 撿, 牛糞, 。\n"
     ]
    }
   ],
   "source": [
    "seg_list = jieba.cut(\"我來到臺灣的臺灣大學\", cut_all=True, HMM=False)\n",
    "print(\"Full Mode: \" + \"/\".join(seg_list))\n",
    "\n",
    "seg_list = jieba.cut(\"我來到臺灣的臺灣大學\", cut_all=False, HMM=True)\n",
    "print(\"Full Mode: \" + \"/\".join(seg_list))\n",
    "\n",
    "seg_list = jieba.cut(\"阿明碩士畢業於台灣大學生物機電所，後來在家撿牛糞。\")\n",
    "print(\"精確模式: \" + \", \".join(seg_list))\n",
    "\n",
    "seg_list = jieba.cut_for_search(\"阿明碩士畢業於台灣大學生物機電所，後來在家撿牛糞。\")\n",
    "print(\"搜尋引擎模式: \" + \", \".join(seg_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "會發現在搜尋引擎模式中, 台灣大學又被分成更細的兩項: 台灣, 大學."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 基於TF-IDF算法的關鍵字提取\n",
    "**analyse.extract_tags(sentence, topK=20, withWeight=False, allowPOS=())**:\n",
    "    * sentence: 待分詞的文本.\n",
    "    * topK: 決定返回多少個權重值最大的關鍵詞.\n",
    "    * withWeight: 是否返回權重值.\n",
    "    * allowPOS: 設定僅包括指定詞性的詞."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.A import jieba.analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba.analyse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.B jieba.analyse.extract_tags()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "不厭,4879\n",
      "周公吐哺,2612\n",
      "對酒當歌,2439\n",
      "幾何,2439\n",
      "日苦,2439\n",
      "慨當,2439\n",
      "憂思,2439\n",
      "難忘,2439\n",
      "解憂,2439\n",
      "為君,2439\n"
     ]
    }
   ],
   "source": [
    "data = \"對酒當歌，人生幾何？譬如朝露，去日苦多。慨當以慷，憂思難忘。何以解憂？唯有杜康。青青子衿，悠悠我心。但為君故，沉吟至今。呦呦鹿鳴，食野之苹。我有嘉賓，鼓瑟吹笙。明明如月，何時可掇？憂從中來，不可斷絕。越陌度阡，枉用相存。契闊談讌，心念舊恩。月明星稀，烏鵲南飛。繞樹三匝，何枝可依？山不厭高，海不厭深。周公吐哺，天下歸心。\"\n",
    "tags = jieba.analyse.extract_tags(data, topK=10, withWeight=True)\n",
    "for tag, weight in tags:\n",
    "    print(tag + \",\" + str(int(weight * 10000)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
